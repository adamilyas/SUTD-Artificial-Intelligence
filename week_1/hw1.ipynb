{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`imageclef2011` image features, the set of all\n",
    "labels in `concepts_2011.txt` and the image labels `trainset_gt_annotations.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['9' 'Spring']\n",
      " ['10' 'Summer']\n",
      " ['11' 'Autumn']\n",
      " ['12' 'Winter']]\n"
     ]
    }
   ],
   "source": [
    "concepts = np.loadtxt('./data/concepts_2011.txt', dtype=str)\n",
    "print(concepts[10:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1353, 5)\n",
      "                                          0   10  11  12  13\n",
      "16  01d88c87-f2e3-4a7f-be26-b38c549b5e7d.jpg   1   0   0   0\n",
      "33  03b0bf90-f66b-41ad-b7ae-0e9f818cb9fd.jpg   0   1   0   0\n",
      "34  03c6c5ed-188b-4034-a487-de10aa3aac0d.jpg   0   0   0   1\n",
      "37  03e489e7-7c0f-48f3-971d-b44b7e026f25.jpg   0   1   0   0\n",
      "43  040b9239-da83-462b-991e-c4f2a1898a62.jpg   0   1   0   0\n"
     ]
    }
   ],
   "source": [
    "labelled = pd.read_csv('./data/trainset_gt_annotations.txt', sep=' ', header=None)\n",
    "# COL MAP:\n",
    "    # 0: file_name\n",
    "    # 1 - 99: concepts\n",
    "df_labels = labelled[[0, 10, 11, 12, 13]]\n",
    "df_labels = df_labels[(df_labels[10] == 1) | (df_labels[11] == 1) | (df_labels[12] == 1) | (df_labels[13] == 1)]\n",
    "print(df_labels.shape)\n",
    "print(df_labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"./data/imageclef2011_feats/\")\n",
    "npy_files = os.listdir()\n",
    "file_end = \"_ft.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1353\n",
      "(1353, 1024)\n"
     ]
    }
   ],
   "source": [
    "N = len(df_labels.index) # 1353\n",
    "features = np.zeros((N, 1024))\n",
    "for i in range(N):\n",
    "    file_name = df_labels.iloc[i][0] + file_end\n",
    "    arr = np.load(file_name)\n",
    "    features[i] = arr\n",
    "    \n",
    "print(N)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.092691</td>\n",
       "      <td>0.143073</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.244339</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155491</td>\n",
       "      <td>0.033567</td>\n",
       "      <td>0.884194</td>\n",
       "      <td>1.652364</td>\n",
       "      <td>3.855961</td>\n",
       "      <td>0.055550</td>\n",
       "      <td>0.127505</td>\n",
       "      <td>2.406339</td>\n",
       "      <td>0.075314</td>\n",
       "      <td>0.061892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.054378</td>\n",
       "      <td>0.913825</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.103398</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>...</td>\n",
       "      <td>1.430287</td>\n",
       "      <td>0.596499</td>\n",
       "      <td>2.473551</td>\n",
       "      <td>2.021996</td>\n",
       "      <td>2.559144</td>\n",
       "      <td>3.585923</td>\n",
       "      <td>0.391455</td>\n",
       "      <td>0.465208</td>\n",
       "      <td>1.017973</td>\n",
       "      <td>2.098028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.009949</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.119458</td>\n",
       "      <td>1.603592</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.504032</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016409</td>\n",
       "      <td>0.552168</td>\n",
       "      <td>0.929716</td>\n",
       "      <td>0.039299</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>1.456054</td>\n",
       "      <td>1.377030</td>\n",
       "      <td>1.677010</td>\n",
       "      <td>0.064636</td>\n",
       "      <td>1.076554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.033131</td>\n",
       "      <td>0.376466</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.287925</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371879</td>\n",
       "      <td>2.791942</td>\n",
       "      <td>3.884916</td>\n",
       "      <td>0.773607</td>\n",
       "      <td>0.724978</td>\n",
       "      <td>0.555365</td>\n",
       "      <td>1.499820</td>\n",
       "      <td>1.941962</td>\n",
       "      <td>2.903649</td>\n",
       "      <td>2.013276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.192029</td>\n",
       "      <td>0.387356</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>...</td>\n",
       "      <td>6.574651</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>1.287308</td>\n",
       "      <td>0.334603</td>\n",
       "      <td>0.241196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.480002</td>\n",
       "      <td>0.072667</td>\n",
       "      <td>0.755902</td>\n",
       "      <td>0.374753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "16  0.000487  0.005092  0.002814  0.000255  0.092691  0.143073  0.000282   \n",
       "33  0.000299  0.006495  0.005325  0.004764  0.054378  0.913825  0.000410   \n",
       "34  0.000334  0.009949  0.001487  0.002653  0.119458  1.603592  0.000545   \n",
       "37  0.000495  0.004574  0.003922  0.005027  0.033131  0.376466  0.000441   \n",
       "43  0.000150  0.006658  0.000929  0.001262  0.192029  0.387356  0.000796   \n",
       "\n",
       "        7         8         9       ...         1014      1015      1016  \\\n",
       "16  0.005021  0.244339  0.000229    ...     0.155491  0.033567  0.884194   \n",
       "33  0.002364  0.103398  0.000597    ...     1.430287  0.596499  2.473551   \n",
       "34  0.001888  0.504032  0.000396    ...     1.016409  0.552168  0.929716   \n",
       "37  0.001464  0.287925  0.000253    ...     0.371879  2.791942  3.884916   \n",
       "43  0.002781  0.274344  0.000517    ...     6.574651  0.735099  1.287308   \n",
       "\n",
       "        1017      1018      1019      1020      1021      1022      1023  \n",
       "16  1.652364  3.855961  0.055550  0.127505  2.406339  0.075314  0.061892  \n",
       "33  2.021996  2.559144  3.585923  0.391455  0.465208  1.017973  2.098028  \n",
       "34  0.039299  0.356691  1.456054  1.377030  1.677010  0.064636  1.076554  \n",
       "37  0.773607  0.724978  0.555365  1.499820  1.941962  2.903649  2.013276  \n",
       "43  0.334603  0.241196  0.000000  1.480002  0.072667  0.755902  0.374753  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = pd.DataFrame(features, index=df_labels.index)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the images into\n",
    "- 60 percent per class for training\n",
    "- 10 percent per class for validation, \n",
    "- 30 percent per class for final test. \n",
    "\n",
    "What is the difference to a random 60 âˆ’ 10 âˆ’ 30 split of the whole data as compared to split\n",
    "class-wise? \n",
    "\n",
    "Why I asked you to split classwise ? Explain in at most 8 sentences.\n",
    "\n",
    "idea: use a linear SVM (e.g. scikit-learn) with python3 interface. If you\n",
    "use another kernel, please notify clearly in the report.\n",
    "\n",
    "for the first experiment take only the features from those images who have\n",
    "as label either spring or summer or winter or fall. that should be 1353\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, train=0.6, test=0.3, val=0.1):\n",
    "    N = len(data)\n",
    "    index = list(data.index)\n",
    "    \n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    first_partition = int(N*train)\n",
    "    second_partition = int(N*train) + int(N*test)\n",
    "    \n",
    "    train_index = index[:first_partition]\n",
    "    test_index = index[first_partition: second_partition]\n",
    "    val_index = index[second_partition: ]\n",
    "    \n",
    "    train = data.loc[train_index]\n",
    "    test = data.loc[test_index]\n",
    "    val = data.loc[val_index]\n",
    "    \n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_map = {10: 'Spring', 11: 'Summer', 12: 'Autumn', 13: 'Winter'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert multilabel to multiclass\n",
    "# for season in seasons_map:\n",
    "def label_helper(row):\n",
    "    for season in seasons_map:\n",
    "        if row[season] == 1:\n",
    "            return season\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_labels.apply(label_helper, axis=1)\n",
    "df_features[\"labels\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.092691</td>\n",
       "      <td>0.143073</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.244339</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033567</td>\n",
       "      <td>0.884194</td>\n",
       "      <td>1.652364</td>\n",
       "      <td>3.855961</td>\n",
       "      <td>0.055550</td>\n",
       "      <td>0.127505</td>\n",
       "      <td>2.406339</td>\n",
       "      <td>0.075314</td>\n",
       "      <td>0.061892</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.054378</td>\n",
       "      <td>0.913825</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.103398</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596499</td>\n",
       "      <td>2.473551</td>\n",
       "      <td>2.021996</td>\n",
       "      <td>2.559144</td>\n",
       "      <td>3.585923</td>\n",
       "      <td>0.391455</td>\n",
       "      <td>0.465208</td>\n",
       "      <td>1.017973</td>\n",
       "      <td>2.098028</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.009949</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.119458</td>\n",
       "      <td>1.603592</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.504032</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552168</td>\n",
       "      <td>0.929716</td>\n",
       "      <td>0.039299</td>\n",
       "      <td>0.356691</td>\n",
       "      <td>1.456054</td>\n",
       "      <td>1.377030</td>\n",
       "      <td>1.677010</td>\n",
       "      <td>0.064636</td>\n",
       "      <td>1.076554</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.033131</td>\n",
       "      <td>0.376466</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.287925</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>...</td>\n",
       "      <td>2.791942</td>\n",
       "      <td>3.884916</td>\n",
       "      <td>0.773607</td>\n",
       "      <td>0.724978</td>\n",
       "      <td>0.555365</td>\n",
       "      <td>1.499820</td>\n",
       "      <td>1.941962</td>\n",
       "      <td>2.903649</td>\n",
       "      <td>2.013276</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.192029</td>\n",
       "      <td>0.387356</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>1.287308</td>\n",
       "      <td>0.334603</td>\n",
       "      <td>0.241196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.480002</td>\n",
       "      <td>0.072667</td>\n",
       "      <td>0.755902</td>\n",
       "      <td>0.374753</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000487  0.005092  0.002814  0.000255  0.092691  0.143073  0.000282   \n",
       "1  0.000299  0.006495  0.005325  0.004764  0.054378  0.913825  0.000410   \n",
       "2  0.000334  0.009949  0.001487  0.002653  0.119458  1.603592  0.000545   \n",
       "3  0.000495  0.004574  0.003922  0.005027  0.033131  0.376466  0.000441   \n",
       "4  0.000150  0.006658  0.000929  0.001262  0.192029  0.387356  0.000796   \n",
       "\n",
       "          7         8         9   ...        1015      1016      1017  \\\n",
       "0  0.005021  0.244339  0.000229   ...    0.033567  0.884194  1.652364   \n",
       "1  0.002364  0.103398  0.000597   ...    0.596499  2.473551  2.021996   \n",
       "2  0.001888  0.504032  0.000396   ...    0.552168  0.929716  0.039299   \n",
       "3  0.001464  0.287925  0.000253   ...    2.791942  3.884916  0.773607   \n",
       "4  0.002781  0.274344  0.000517   ...    0.735099  1.287308  0.334603   \n",
       "\n",
       "       1018      1019      1020      1021      1022      1023  labels  \n",
       "0  3.855961  0.055550  0.127505  2.406339  0.075314  0.061892      10  \n",
       "1  2.559144  3.585923  0.391455  0.465208  1.017973  2.098028      11  \n",
       "2  0.356691  1.456054  1.377030  1.677010  0.064636  1.076554      13  \n",
       "3  0.724978  0.555365  1.499820  1.941962  2.903649  2.013276      11  \n",
       "4  0.241196  0.000000  1.480002  0.072667  0.755902  0.374753      11  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = df_features.reset_index(drop=True)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as `.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_val = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "for season in seasons_map:\n",
    "    df_season = df_features[df_features[\"labels\"] == season]\n",
    "    train, test, val = split_data(df_season)\n",
    "    df_train = pd.concat([df_train, train])\n",
    "    df_val = pd.concat([df_val, val])\n",
    "    df_test = pd.concat([df_test, test])\n",
    "\n",
    "np.save(\"../df_train.npy\", df_train.values)\n",
    "np.save(\"../df_val.npy\", df_val.values)\n",
    "np.save(\"../df_test.npy\", df_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xy(df, label_name, label):\n",
    "    X = df.drop('labels', axis=1).values\n",
    "    y = df[label_name]\n",
    "    y = [1 if el == label else 0 for el in y]\n",
    "    return X, y\n",
    "\n",
    "def classwise_accuracy(y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    N = len(y_true)\n",
    "    A = 0\n",
    "    for c in classes:\n",
    "        n_count = 0\n",
    "        correct = 0\n",
    "        for i in range(N):\n",
    "            if y_true[i] == c:\n",
    "                n_count += 1\n",
    "                if y_pred[i] == c:\n",
    "                    correct += 1\n",
    "                    \n",
    "        A += correct/n_count\n",
    "    return A/len(classes)\n",
    "\n",
    "def vanilla_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Season: Spring\n",
      "Vanilla\n",
      "Best Constant: 0.01, Acc: 0.9136690647482014\n",
      "Classwise\n",
      "Best Constant: 0.01, Acc: 0.6664179104477612\n",
      "\n",
      "Season: Summer\n",
      "Vanilla\n",
      "Best Constant: 0.01, Acc: 0.7194244604316546\n",
      "Classwise\n",
      "Best Constant: 0.01, Acc: 0.6940898345153664\n",
      "\n",
      "Season: Autumn\n",
      "Vanilla\n",
      "Best Constant: 0.01, Acc: 0.9064748201438849\n",
      "Classwise\n",
      "Best Constant: 0.01, Acc: 0.8112403100775194\n",
      "\n",
      "Season: Winter\n",
      "Vanilla\n",
      "Best Constant: 0.01, Acc: 0.8561151079136691\n",
      "Classwise\n",
      "Best Constant: 0.01, Acc: 0.7284044715447154\n"
     ]
    }
   ],
   "source": [
    "constants = [0.01, 0.1, 0.1**0.5, 1., 10**0.5, 10]\n",
    "\n",
    "for season in seasons_map:\n",
    "    X_train, y_train = generate_xy(df_train, 'labels', season)\n",
    "    X_val, y_val = generate_xy(df_val, 'labels', season)\n",
    "    X_test, y_test = generate_xy(df_test, 'labels', season)\n",
    "\n",
    "    best_vanilla_c = None\n",
    "    best_classwise_c = None\n",
    "    \n",
    "    best_vanilla_acc = 0\n",
    "    best_classwise_acc = 0 \n",
    "    print(f\"\\nSeason: {seasons_map[season]}\")\n",
    "    for i in range(len(constants)):\n",
    "        C = constants[i]\n",
    "        clf = LinearSVC(C=C)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "\n",
    "        current_vanilla_acc = vanilla_accuracy(y_val_pred, y_val)\n",
    "        current_classwise_acc = classwise_accuracy(y_val_pred, y_val)\n",
    "        \n",
    "#         print(f\"Constant: {C}, V Acc: {current_vanilla_acc}, Classwise Acc: {current_classwise_acc}\")\n",
    "        \n",
    "        if current_vanilla_acc > best_vanilla_acc:\n",
    "            best_vanilla_c = C\n",
    "            best_vanilla_acc = current_vanilla_acc\n",
    "            \n",
    "        if current_classwise_acc > best_classwise_acc:\n",
    "            best_classwise_c = C\n",
    "            best_classwise_acc = current_classwise_acc\n",
    "\n",
    "    print(f\"Vanilla\")\n",
    "    print(f\"Best Constant: {best_vanilla_c}, Acc: {best_vanilla_acc}\")\n",
    "    print(f\"Classwise\")\n",
    "    print(f\"Best Constant: {best_classwise_c}, Acc: {best_classwise_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = [0.01, 0.1, 0.1**0.5, 1., 10**0.5, 10]\n",
    "\n",
    "for season in seasons_map:\n",
    "    X_train, y_train = generate_xy(df_train, 'labels', season)\n",
    "    X_val, y_val = generate_xy(df_val, 'labels', season)\n",
    "    X_test, y_test = generate_xy(df_test, 'labels', season)\n",
    "\n",
    "    best_vanilla_c = None\n",
    "    best_classwise_c = None\n",
    "    \n",
    "    best_vanilla_acc = 0\n",
    "    best_classwise_acc = 0  \n",
    "    for i in range(len(constants)):\n",
    "        C = constants[i]\n",
    "        clf = LinearSVC(C=C)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "\n",
    "        current_vanilla_acc = vanilla_accuracy(y_val_pred, y_val)\n",
    "        current_classwise_acc = classwise_accuracy(y_val_pred, y_val)\n",
    "        \n",
    "        if current_vanilla_acc > best_vanilla_acc:\n",
    "            best_vanilla_c = C\n",
    "            best_vanilla_acc = current_vanilla_acc\n",
    "            \n",
    "        if current_classwise_acc > best_classwise_acc:\n",
    "            best_classwise_c = C\n",
    "            best_vanilla_acc = current_vanilla_acc\n",
    "\n",
    "    print(f\"Season: {seasons_map[season]}\")\n",
    "    clf = LinearSVC(C=best_c)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = np.mean(y_pred == y_test)\n",
    "    \n",
    "    print(f\"Best C: {round(best_c, 3)}, Val. Acc: {best_acc}, Test Acc: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classwise Accuracy \n",
    "\n",
    "$$\n",
    "\\begin{aligned} A &=\\frac{1}{C} \\sum_{c=1}^{C} a_{c} \\\\ a_{c} &=\\frac{1}{\\sum_{i=1}^{n} 1\\left[y_{i}==c\\right]} \\sum_{i=1}^{n} 1\\left[y_{i}==c\\right] 1\\left[f\\left(x_{i}\\right)==c\\right] \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That results in a multi-class dataset with mutually exclusive labels. Thus\n",
    "you can train 4 binary svms, one for each class in one-vs-all manner. Each\n",
    "svm is trained on the training dataset using all the training data.\n",
    "\n",
    "This method has one free parameter - the regularization constant. \n",
    "\n",
    "Find the best regularization constant from the set $0.01,0.1,0.1^{0.5}, 1,10^{0.5}, 10,100^{0.5}$\n",
    "by repeatedly training on the training set and measuring performance on\n",
    "the validation set. Use as performance measure the class-wise accuracy\n",
    "averaged over all 4 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the images into \n",
    "- 60 percent per class for training, \n",
    "- 10 percent per class for validation, \n",
    "- 30 percent per class for final test. \n",
    "\n",
    "What is the difference\n",
    "to a random 60 âˆ’ 10 âˆ’ 30 split of the whole data as compared to split\n",
    "class-wise? Why I asked you to split classwise ? Explain in at most 8\n",
    "sentences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
